{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in /home/edward/.local/lib/python3.8/site-packages (0.8)\n",
      "Requirement already satisfied: gensim in /home/edward/.local/lib/python3.8/site-packages (4.3.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/edward/.local/lib/python3.8/site-packages (from gensim) (1.9.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/edward/.local/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/edward/.local/lib/python3.8/site-packages (from gensim) (1.22.3)\n",
      "Requirement already satisfied: keras in /home/edward/.local/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: nltk in /home/edward/.local/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in /home/edward/.local/lib/python3.8/site-packages (from nltk) (4.63.1)\n",
      "Requirement already satisfied: joblib in /home/edward/.local/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/edward/.local/lib/python3.8/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: click in /home/edward/.local/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already up-to-date: scikit-learn in /home/edward/.local/lib/python3.8/site-packages (1.2.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.17.3 in /home/edward/.local/lib/python3.8/site-packages (from scikit-learn) (1.22.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.3.2 in /home/edward/.local/lib/python3.8/site-packages (from scikit-learn) (1.9.2)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /home/edward/.local/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=1.1.1 in /home/edward/.local/lib/python3.8/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: python-docx in /home/edward/.local/lib/python3.8/site-packages (0.8.11)\n",
      "Requirement already satisfied: lxml>=2.3.2 in /home/edward/.local/lib/python3.8/site-packages (from python-docx) (4.6.3)\n",
      "Requirement already satisfied: tensorflow in /home/edward/.local/lib/python3.8/site-packages (2.12.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: jax>=0.3.15 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (0.4.10)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (1.49.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\" in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (0.27.0)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (1.22.3)\n",
      "Requirement already satisfied: packaging in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (2.12.3)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (4.23.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorflow) (22.9.24)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in /home/edward/.local/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: scipy>=1.7 in /home/edward/.local/lib/python3.8/site-packages (from jax>=0.3.15->tensorflow) (1.9.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/edward/.local/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.7)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/edward/.local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/edward/.local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/edward/.local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /home/edward/.local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/edward/.local/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.30.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/edward/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/edward/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /home/edward/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/edward/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/edward/.local/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/edward/.local/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2019.11.28)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/edward/.local/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: nltk in /home/edward/.local/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: click in /home/edward/.local/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /home/edward/.local/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /home/edward/.local/lib/python3.8/site-packages (from nltk) (4.63.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/edward/.local/lib/python3.8/site-packages (from nltk) (2022.3.15)\n",
      "Requirement already satisfied: spacy in /home/edward/.local/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (45.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (4.63.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (2.30.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: jinja2 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/edward/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/edward/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/edward/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/edward/.local/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/edward/.local/lib/python3.8/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/edward/.local/lib/python3.8/site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/edward/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/edward/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
      "docx2csv exists.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Dependencies\n",
    "pip install docx2txt\n",
    "pip install gensim\n",
    "pip install keras\n",
    "pip install nltk\n",
    "pip install -U scikit-learn\n",
    "pip install python-docx\n",
    "pip install tensorflow\n",
    "pip install nltk\n",
    "pip install spacy\n",
    "\n",
    "if ls docx2csv >/dev/null 2>&1; then\n",
    "    echo \"docx2csv exists.\"\n",
    "else\n",
    "    echo \"Folder does not exist. Cloning docx2csv.\"\n",
    "    git clone https://github.com/ivbeg/docx2csv.git\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running install\n",
      "running bdist_egg\n",
      "running egg_info\n",
      "writing docx2csv.egg-info/PKG-INFO\n",
      "writing dependency_links to docx2csv.egg-info/dependency_links.txt\n",
      "writing entry points to docx2csv.egg-info/entry_points.txt\n",
      "writing requirements to docx2csv.egg-info/requires.txt\n",
      "writing top-level names to docx2csv.egg-info/top_level.txt\n",
      "reading manifest file 'docx2csv.egg-info/SOURCES.txt'\n",
      "writing manifest file 'docx2csv.egg-info/SOURCES.txt'\n",
      "installing library code to build/bdist.linux-x86_64/egg\n",
      "running install_lib\n",
      "running build_py\n",
      "creating build/bdist.linux-x86_64/egg\n",
      "creating build/bdist.linux-x86_64/egg/docx2csv\n",
      "copying build/lib/docx2csv/converter.py -> build/bdist.linux-x86_64/egg/docx2csv\n",
      "copying build/lib/docx2csv/core.py -> build/bdist.linux-x86_64/egg/docx2csv\n",
      "copying build/lib/docx2csv/__init__.py -> build/bdist.linux-x86_64/egg/docx2csv\n",
      "copying build/lib/docx2csv/__main__.py -> build/bdist.linux-x86_64/egg/docx2csv\n",
      "byte-compiling build/bdist.linux-x86_64/egg/docx2csv/converter.py to converter.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/docx2csv/core.py to core.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/docx2csv/__init__.py to __init__.cpython-38.pyc\n",
      "byte-compiling build/bdist.linux-x86_64/egg/docx2csv/__main__.py to __main__.cpython-38.pyc\n",
      "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying docx2csv.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying docx2csv.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying docx2csv.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying docx2csv.egg-info/entry_points.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying docx2csv.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying docx2csv.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "copying docx2csv.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
      "creating 'dist/docx2csv-0.1.2-py3.8.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
      "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
      "Processing docx2csv-0.1.2-py3.8.egg\n",
      "removing '/usr/local/lib/python3.8/dist-packages/docx2csv-0.1.2-py3.8.egg' (and everything under it)\n",
      "creating /usr/local/lib/python3.8/dist-packages/docx2csv-0.1.2-py3.8.egg\n",
      "Extracting docx2csv-0.1.2-py3.8.egg to /usr/local/lib/python3.8/dist-packages\n",
      "docx2csv 0.1.2 is already the active version in easy-install.pth\n",
      "Installing docx2csv script to /usr/local/bin\n",
      "\n",
      "Installed /usr/local/lib/python3.8/dist-packages/docx2csv-0.1.2-py3.8.egg\n",
      "Processing dependencies for docx2csv==0.1.2\n",
      "Searching for xlwt==1.3.0\n",
      "Best match: xlwt 1.3.0\n",
      "Processing xlwt-1.3.0-py3.8.egg\n",
      "xlwt 1.3.0 is already the active version in easy-install.pth\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages/xlwt-1.3.0-py3.8.egg\n",
      "Searching for openpyxl==3.2.0b1\n",
      "Best match: openpyxl 3.2.0b1\n",
      "Processing openpyxl-3.2.0b1-py3.8.egg\n",
      "openpyxl 3.2.0b1 is already the active version in easy-install.pth\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages/openpyxl-3.2.0b1-py3.8.egg\n",
      "Searching for docx==0.2.4\n",
      "Best match: docx 0.2.4\n",
      "Processing docx-0.2.4-py3.8.egg\n",
      "docx 0.2.4 is already the active version in easy-install.pth\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages/docx-0.2.4-py3.8.egg\n",
      "Searching for Click==7.0\n",
      "Best match: Click 7.0\n",
      "Adding Click 7.0 to easy-install.pth file\n",
      "\n",
      "Using /usr/lib/python3/dist-packages\n",
      "Searching for et-xmlfile==1.1.0\n",
      "Best match: et-xmlfile 1.1.0\n",
      "Processing et_xmlfile-1.1.0-py3.8.egg\n",
      "et-xmlfile 1.1.0 is already the active version in easy-install.pth\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages/et_xmlfile-1.1.0-py3.8.egg\n",
      "Searching for lxml==4.9.2\n",
      "Best match: lxml 4.9.2\n",
      "Processing lxml-4.9.2-py3.8-linux-x86_64.egg\n",
      "lxml 4.9.2 is already the active version in easy-install.pth\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages/lxml-4.9.2-py3.8-linux-x86_64.egg\n",
      "Searching for Pillow==9.5.0\n",
      "Best match: Pillow 9.5.0\n",
      "Processing Pillow-9.5.0-py3.8-linux-x86_64.egg\n",
      "Pillow 9.5.0 is already the active version in easy-install.pth\n",
      "\n",
      "Using /usr/local/lib/python3.8/dist-packages/Pillow-9.5.0-py3.8-linux-x86_64.egg\n",
      "Finished processing dependencies for docx2csv==0.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[sudo] password for edward: "
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "source .env\n",
    "cd docx2csv && echo \"$PASSWORD\" | sudo -S python3 setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- TEST DATA INPUT -----\n",
    "\n",
    "# Computer Science Test Data.\n",
    "# CURRENT_MAPPING=\"Lists_ComputerScience.docx\"\n",
    "# ORIGINAL_MAPPING=\"Original-Mapping-ComputerScience.csv\"\n",
    "\n",
    "# InformationSecurity Test Data.\n",
    "CURRENT_MAPPING=\"Lists_InformationSecurity.docx\"\n",
    "ORIGINAL_MAPPING=\"Original-Mapping-InfoSecurity.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/edward/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/edward/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/edward/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract tables from word document\n",
    "from docx2csv import extract_tables, extract\n",
    "tables = extract_tables(CURRENT_MAPPING)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "document = Document(CURRENT_MAPPING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Analyze',\n",
       "  'complex',\n",
       "  'computing',\n",
       "  'problem',\n",
       "  'apply',\n",
       "  'principle',\n",
       "  'computing',\n",
       "  'relevant',\n",
       "  'discipline',\n",
       "  'identify',\n",
       "  'solution',\n",
       "  '.'],\n",
       " ['Design',\n",
       "  ',',\n",
       "  'implement',\n",
       "  ',',\n",
       "  'evaluate',\n",
       "  'computing-based',\n",
       "  'solution',\n",
       "  'meet',\n",
       "  'given',\n",
       "  'set',\n",
       "  'computing',\n",
       "  'requirement',\n",
       "  'context',\n",
       "  'program',\n",
       "  '’',\n",
       "  'discipline',\n",
       "  '.'],\n",
       " ['Communicate', 'effectively', 'variety', 'professional', 'context', '.'],\n",
       " ['Recognize',\n",
       "  'professional',\n",
       "  'responsibility',\n",
       "  'make',\n",
       "  'informed',\n",
       "  'judgment',\n",
       "  'computing',\n",
       "  'practice',\n",
       "  'based',\n",
       "  'legal',\n",
       "  'ethical',\n",
       "  'principle',\n",
       "  '.'],\n",
       " ['Function',\n",
       "  'effectively',\n",
       "  'member',\n",
       "  'leader',\n",
       "  'team',\n",
       "  'engaged',\n",
       "  'activity',\n",
       "  'appropriate',\n",
       "  'program',\n",
       "  '’',\n",
       "  'discipline',\n",
       "  '.'],\n",
       " ['Apply',\n",
       "  'security',\n",
       "  'principle',\n",
       "  'practice',\n",
       "  'maintain',\n",
       "  'operation',\n",
       "  'presence',\n",
       "  'risk',\n",
       "  'threat',\n",
       "  '.'],\n",
       " ['Demonstrate',\n",
       "  'computational',\n",
       "  'thinking',\n",
       "  'skill',\n",
       "  'solve',\n",
       "  'computing',\n",
       "  'problem'],\n",
       " ['Describe',\n",
       "  'system',\n",
       "  'component',\n",
       "  'involved',\n",
       "  'building',\n",
       "  'usable',\n",
       "  'computing',\n",
       "  'platform'],\n",
       " ['Identify', 'different', 'tool', 'technique', 'used', 'system'],\n",
       " ['Discuss', 'related', 'ethical', 'issue'],\n",
       " ['Translate',\n",
       "  'problem',\n",
       "  'expressed',\n",
       "  'English',\n",
       "  ',',\n",
       "  'mathematics',\n",
       "  'diagram',\n",
       "  'computer',\n",
       "  'program'],\n",
       " ['Implement',\n",
       "  'algorithm',\n",
       "  'using',\n",
       "  'programming',\n",
       "  'construct',\n",
       "  '(',\n",
       "  'variable',\n",
       "  ',',\n",
       "  'control',\n",
       "  'structure',\n",
       "  ',',\n",
       "  'method',\n",
       "  ')'],\n",
       " ['Solve', 'problem', 'using', 'suitable', 'data', 'structure'],\n",
       " ['Implement', 'searching', ',', 'summing', 'selecting', 'algorithm'],\n",
       " ['Design', 'implement', 'algorithm', 'solve', 'simple', 'problem'],\n",
       " ['Choose', 'suitable', 'data', 'type', 'represent', 'information'],\n",
       " ['Apply',\n",
       "  'sequence',\n",
       "  ',',\n",
       "  'selection',\n",
       "  'repetition',\n",
       "  'structure',\n",
       "  'solve',\n",
       "  'problem'],\n",
       " ['Design', 'implement', 'program', 'containing', 'many', 'method'],\n",
       " ['Manipulate', 'One-Dimension', 'Two-Dimension', 'array'],\n",
       " ['Use',\n",
       "  'formal',\n",
       "  'method',\n",
       "  'symbolic',\n",
       "  'proposition',\n",
       "  'evaluate',\n",
       "  'elementary',\n",
       "  'mathematical',\n",
       "  'argument',\n",
       "  'identify',\n",
       "  'logical',\n",
       "  'reasoning'],\n",
       " ['Prove',\n",
       "  'assertion',\n",
       "  'using',\n",
       "  'basic',\n",
       "  'proof',\n",
       "  'method',\n",
       "  ',',\n",
       "  '(',\n",
       "  'eg',\n",
       "  'induction',\n",
       "  ',',\n",
       "  'contrapositive',\n",
       "  ',',\n",
       "  'contradiction',\n",
       "  ',',\n",
       "  '…etc',\n",
       "  ')'],\n",
       " ['Derive', 'closed-forms', 'summation', 'recursive', 'structure'],\n",
       " ['Apply',\n",
       "  'graph',\n",
       "  'theory',\n",
       "  'tree',\n",
       "  'model',\n",
       "  'solve',\n",
       "  'problem',\n",
       "  'connectivity'],\n",
       " ['Use',\n",
       "  'logical',\n",
       "  'notation',\n",
       "  'define',\n",
       "  'reason',\n",
       "  'fundamental',\n",
       "  'mathematical',\n",
       "  'concept',\n",
       "  'set',\n",
       "  ',',\n",
       "  'relation',\n",
       "  ',',\n",
       "  'function',\n",
       "  ',',\n",
       "  'matrix',\n",
       "  'integer'],\n",
       " ['Convert',\n",
       "  'different',\n",
       "  'number',\n",
       "  'system',\n",
       "  'represent',\n",
       "  'signed',\n",
       "  'number',\n",
       "  '1',\n",
       "  \"'s\",\n",
       "  '2',\n",
       "  \"'s\",\n",
       "  'complement',\n",
       "  'representation'],\n",
       " ['Analyze', 'combinational', 'sequential', 'circuit'],\n",
       " ['Design', 'implement', 'combinational', 'sequential', 'circuit'],\n",
       " ['Define',\n",
       "  'modern',\n",
       "  'computer',\n",
       "  'system',\n",
       "  \"'s\",\n",
       "  'major',\n",
       "  'component',\n",
       "  ',',\n",
       "  'function',\n",
       "  'inter-relationships'],\n",
       " ['Explain',\n",
       "  'memory',\n",
       "  'hierarchy',\n",
       "  'structure',\n",
       "  'importance',\n",
       "  'characteristic',\n",
       "  'level'],\n",
       " ['Describe',\n",
       "  'component',\n",
       "  'instruction',\n",
       "  'set',\n",
       "  'different',\n",
       "  'type',\n",
       "  'instruction',\n",
       "  'addressing',\n",
       "  'mode'],\n",
       " ['Explain', 'different', 'concept', 'function', 'physical', 'layer'],\n",
       " ['Apply',\n",
       "  'different',\n",
       "  'mechanism',\n",
       "  'error',\n",
       "  'control',\n",
       "  ',',\n",
       "  'flow',\n",
       "  'control',\n",
       "  'medium',\n",
       "  'access',\n",
       "  'control',\n",
       "  'data',\n",
       "  'link',\n",
       "  'layer'],\n",
       " ['Explain',\n",
       "  'main',\n",
       "  'function',\n",
       "  'network',\n",
       "  'layer',\n",
       "  'packet',\n",
       "  'switching',\n",
       "  ',',\n",
       "  'IP',\n",
       "  'addressing',\n",
       "  'fragmentation'],\n",
       " ['Discuss',\n",
       "  'operation',\n",
       "  'function',\n",
       "  'different',\n",
       "  'Transport',\n",
       "  'layer',\n",
       "  'protocol'],\n",
       " ['Implement', 'class', 'solve', 'given', 'problem'],\n",
       " ['Test', 'simple', 'class'],\n",
       " ['Design', 'class', 'using', 'existing', 'class', 'library'],\n",
       " ['Develop', 'class', 'hierarchy', 'using', 'inheritance'],\n",
       " ['Develop', 'class', 'simple', 'data', 'structure'],\n",
       " ['Design',\n",
       "  'implement',\n",
       "  'small',\n",
       "  'medium',\n",
       "  'size',\n",
       "  'software',\n",
       "  'problem',\n",
       "  'using',\n",
       "  'object'],\n",
       " ['Use', 'Arrays', 'Array-Lists', 'solving', 'problem'],\n",
       " ['Implement', 'user-defined', 'class', 'solve', 'given', 'problem'],\n",
       " ['Use',\n",
       "  'predefined',\n",
       "  'library',\n",
       "  'develop',\n",
       "  'program',\n",
       "  'graphical',\n",
       "  'user',\n",
       "  'interface'],\n",
       " ['Develop', 'class', 'hierarchy', 'using', 'inheritance'],\n",
       " ['Apply', 'project', 'lifecycle', 'process', 'project'],\n",
       " ['Apply', 'project', 'technique', 'tool', 'manage', 'project'],\n",
       " ['Identify', 'internal', 'external', 'constraint', 'given', 'project'],\n",
       " ['Produce', 'document', 'typically', 'used', 'development', 'project'],\n",
       " ['Demonstrate',\n",
       "  'verbal',\n",
       "  ',',\n",
       "  'written',\n",
       "  'communication',\n",
       "  'skill',\n",
       "  'part',\n",
       "  'team'],\n",
       " ['Explain', 'security', 'policy', ',', 'model', ',', 'mechanism'],\n",
       " ['Discuss', 'operating', 'system', 'security', 'model', 'mechanism'],\n",
       " ['Describe', 'cryptographic', 'technique', 'application'],\n",
       " ['Analyze', 'security', 'threat', 'vulnerability', 'computer', 'system'],\n",
       " ['Define', 'solution', 'defend', 'virus', 'malicious', 'program'],\n",
       " ['Explain', 'logical', 'progression', 'operating', 'system', 'development'],\n",
       " ['Explain', 'necessary', 'component', 'structure', 'operating', 'system'],\n",
       " ['Install', 'customize', 'operating', 'system'],\n",
       " ['Write', 'simple', 'shell', 'script', 'operating', 'system'],\n",
       " ['Evaluate',\n",
       "  'various',\n",
       "  'method',\n",
       "  'process',\n",
       "  'scheduling',\n",
       "  'inter-process',\n",
       "  'communication'],\n",
       " ['Explain', 'file-system', 'concept', 'operation'],\n",
       " ['Apply', 'recursion', 'solve', 'problem'],\n",
       " ['Use',\n",
       "  'APIs',\n",
       "  'implementing',\n",
       "  'moderate',\n",
       "  'size',\n",
       "  'program',\n",
       "  'data',\n",
       "  'structure'],\n",
       " ['Design', 'implement', 'linear', 'data', 'structure'],\n",
       " ['Design', 'implement', 'tree', 'data', 'structure'],\n",
       " ['Model', 'Solve', 'problem', 'using', 'graph'],\n",
       " ['Describe', 'main', 'concept', 'database', 'system'],\n",
       " ['Compare',\n",
       "  'database',\n",
       "  'system',\n",
       "  'approach',\n",
       "  'file-based',\n",
       "  'system',\n",
       "  'approach'],\n",
       " ['Design',\n",
       "  'database',\n",
       "  'using',\n",
       "  'entity-relationship',\n",
       "  'diagram',\n",
       "  '(',\n",
       "  'ERD',\n",
       "  ')'],\n",
       " ['Use',\n",
       "  'Relational',\n",
       "  'Algebra',\n",
       "  'perform',\n",
       "  'various',\n",
       "  'operation',\n",
       "  'relation'],\n",
       " ['Apply', 'normalization', 'database', 'table'],\n",
       " ['Function', 'effectively', 'team', 'create', 'query', 'database'],\n",
       " ['Analyze',\n",
       "  'issue',\n",
       "  'case',\n",
       "  'study',\n",
       "  'using',\n",
       "  'ethical',\n",
       "  'decision',\n",
       "  'making',\n",
       "  'based',\n",
       "  'code',\n",
       "  'ethic',\n",
       "  'formal',\n",
       "  'method'],\n",
       " ['Identify',\n",
       "  'privacy',\n",
       "  ',',\n",
       "  'freedom',\n",
       "  'speech',\n",
       "  'crime',\n",
       "  'issue',\n",
       "  'Cyberspace'],\n",
       " ['Discuss', 'intellectual', 'property', 'software', 'development', 'issue'],\n",
       " ['Discuss', 'implication', 'computing', 'workplace', 'worker', 'employer'],\n",
       " ['Discuss',\n",
       "  'socio-economic',\n",
       "  'implication',\n",
       "  'online',\n",
       "  'community',\n",
       "  'Digital',\n",
       "  'Divide'],\n",
       " ['Function',\n",
       "  'group',\n",
       "  'ass',\n",
       "  'current',\n",
       "  'ethical',\n",
       "  'issue',\n",
       "  'communicate',\n",
       "  'result',\n",
       "  'oral',\n",
       "  'written',\n",
       "  'form'],\n",
       " ['Describe',\n",
       "  'role',\n",
       "  'skill',\n",
       "  'entrepreneur',\n",
       "  'cultivate',\n",
       "  'entrepreneurial',\n",
       "  'mindset'],\n",
       " ['Apply',\n",
       "  'process',\n",
       "  'followed',\n",
       "  'entrepreneur',\n",
       "  'selecting',\n",
       "  'valuable',\n",
       "  'opportunity',\n",
       "  'related',\n",
       "  'business'],\n",
       " ['Explain', 'principle', 'success', 'factor', 'venture', 'planning'],\n",
       " ['Evaluate',\n",
       "  'viability',\n",
       "  'functional',\n",
       "  'planning',\n",
       "  'venture',\n",
       "  ',',\n",
       "  'considering',\n",
       "  'key',\n",
       "  'legal',\n",
       "  'intellectual',\n",
       "  'property',\n",
       "  'issue'],\n",
       " ['Create', 'business', 'model', 'financial', 'plan', 'venture'],\n",
       " ['Identify', 'structure', 'operation', 'workplace'],\n",
       " ['Recognize', 'employee', 'right', 'responsibility'],\n",
       " ['Apply', 'knowledge', 'workplace'],\n",
       " ['Function', 'effectively', ',', 'professionally', 'ethically', 'team'],\n",
       " ['Communicate', 'effectively', 'technically', 'orally', 'writing'],\n",
       " ['Recognize', 'need', 'continuing', 'professional', 'development'],\n",
       " ['Discuss', 'contemporary', 'cryptography', 'application'],\n",
       " ['Apply', 'hash', 'function', 'algorithm'],\n",
       " ['Investigate',\n",
       "  'mathematical',\n",
       "  'concept',\n",
       "  'required',\n",
       "  'cryptographic',\n",
       "  'algorithm'],\n",
       " ['Analyze', 'security', 'threat', 'associated', 'cryptographic', 'algorithm'],\n",
       " ['Evaluate', 'various', 'cryptographic', 'technique'],\n",
       " ['Analyze', 'classic', 'cryptographic', 'algorithm'],\n",
       " ['Implement', 'symmetric', 'cryptography', 'technique'],\n",
       " ['Implement', 'public-key', 'cryptosystems', 'technique'],\n",
       " ['Compare',\n",
       "  'security',\n",
       "  'property',\n",
       "  'well-known',\n",
       "  'cryptographic',\n",
       "  'protocol'],\n",
       " ['Implement', 'IPSec', 'VPN', 'solution', 'small', 'network'],\n",
       " ['Describe', 'TCP/IP', 'protocol', 'common', 'network', 'service'],\n",
       " ['Explain', 'network', 'traffic', 'service', 'filtering', 'concept'],\n",
       " ['Compare', 'stateless', 'stateful', 'firewall'],\n",
       " ['Assess', 'firewall', 'filtering', 'rule', 'consistency', 'efficiency'],\n",
       " ['Discuss', 'VPN', 'secure', 'network', 'architecture'],\n",
       " ['Demonstrate', 'teamwork', 'skill'],\n",
       " ['Describe', 'Internet', 'e-commerce', 'security', 'protocol'],\n",
       " ['Analyze',\n",
       "  'vulnerability',\n",
       "  'associated',\n",
       "  'insecure',\n",
       "  'Internet',\n",
       "  'e-commerce',\n",
       "  'protocol'],\n",
       " ['Demonstrate',\n",
       "  'security',\n",
       "  'protocol',\n",
       "  'used',\n",
       "  'achieve',\n",
       "  'internet',\n",
       "  'e-commerce',\n",
       "  'security'],\n",
       " ['Communicate',\n",
       "  'issue',\n",
       "  'relevant',\n",
       "  'public-key',\n",
       "  'infrastructure',\n",
       "  '(',\n",
       "  'PKI',\n",
       "  ')'],\n",
       " ['Explain',\n",
       "  'concept',\n",
       "  'trust',\n",
       "  '(',\n",
       "  'trust',\n",
       "  'model',\n",
       "  ')',\n",
       "  'internet',\n",
       "  'using',\n",
       "  'secure',\n",
       "  'internet',\n",
       "  'protocol'],\n",
       " ['Discuss', 'common', 'security', 'issue', 'software'],\n",
       " ['Analyze', 'software', 'vulnerability'],\n",
       " ['Explain', 'secure', 'software', 'design', '&', 'development', 'technique'],\n",
       " ['Compare',\n",
       "  'various',\n",
       "  'software',\n",
       "  'security',\n",
       "  'testing',\n",
       "  'tool',\n",
       "  'technique'],\n",
       " ['Analyze', 'web', 'application', 'security', 'threat', 'countermeasure'],\n",
       " ['Discuss', 'system', 'security', 'architecture', 'concept', 'attribute'],\n",
       " ['Design', 'secure', 'information', 'system', 'using', 'OM-AM', 'framework'],\n",
       " ['Apply', 'security', 'access', 'control', 'model'],\n",
       " ['Analyze',\n",
       "  'security',\n",
       "  'threat',\n",
       "  'associated',\n",
       "  'information',\n",
       "  'system',\n",
       "  'infrastructure'],\n",
       " ['Select', 'security', 'countermeasure', 'solution'],\n",
       " ['Evaluate', 'biometric', 'solution', 'authentication', 'protocol'],\n",
       " ['Configure', 'security', 'feature', 'network', 'device'],\n",
       " ['Analyze', 'common', 'network', 'threat', 'attack', 'vector'],\n",
       " ['Apply', 'attack', 'mitigation', 'technique'],\n",
       " ['Implement',\n",
       "  'packet',\n",
       "  'filter',\n",
       "  ',',\n",
       "  'stateful',\n",
       "  'firewall',\n",
       "  ',',\n",
       "  'application',\n",
       "  'layer',\n",
       "  'firewall'],\n",
       " ['Analyze',\n",
       "  'security',\n",
       "  'incident',\n",
       "  'using',\n",
       "  'intrusion',\n",
       "  'detection',\n",
       "  'prevention',\n",
       "  'system'],\n",
       " ['Evaluate', 'operating', 'system', 'security', 'aspect'],\n",
       " ['Configure', 'biometric', 'security', 'system'],\n",
       " ['Implement', 'lattice-based', 'access', 'control', 'model'],\n",
       " ['Design', 'active', 'response', 'security', 'architecture'],\n",
       " ['Use', 'digital', 'forensics', 'hardware', 'software', 'tool'],\n",
       " ['Analyze',\n",
       "  'designing',\n",
       "  'issue',\n",
       "  'pertaining',\n",
       "  'information',\n",
       "  'security',\n",
       "  'policy'],\n",
       " ['Investigate', 'sociological', 'legal', 'issue', 'policy', 'implementation'],\n",
       " ['Apply',\n",
       "  'principle',\n",
       "  'philosophy',\n",
       "  'underlie',\n",
       "  'successful',\n",
       "  'information',\n",
       "  'security',\n",
       "  'governance'],\n",
       " ['Discuss',\n",
       "  'interaction',\n",
       "  'information',\n",
       "  'security',\n",
       "  'concern',\n",
       "  'business',\n",
       "  'objective'],\n",
       " ['Evaluate',\n",
       "  'information',\n",
       "  'security',\n",
       "  'activity',\n",
       "  'within',\n",
       "  'implementation',\n",
       "  'project'],\n",
       " ['Analyze', 'common', 'security', 'threat', 'network', 'attack'],\n",
       " ['Evaluate', 'IPS', 'attack', 'signature', 'rule'],\n",
       " ['Compare', 'appropriate', 'countermeasure', 'common', 'network', 'attack'],\n",
       " ['Discuss', 'system', 'security', 'auditing', 'vulnerability', 'assessment'],\n",
       " ['Demonstrate', 'teamwork', 'skill'],\n",
       " ['Investigate', 'privacy', 'concern', 'different', 'context'],\n",
       " ['Apply', 'privacy', 'protection', 'solution'],\n",
       " ['Analyze',\n",
       "  'shortcoming',\n",
       "  'existing',\n",
       "  'privacy',\n",
       "  'technology',\n",
       "  'challenge',\n",
       "  'privacy',\n",
       "  'protection'],\n",
       " ['Discuss',\n",
       "  'privacy',\n",
       "  'legislation',\n",
       "  ',',\n",
       "  'policy',\n",
       "  'best',\n",
       "  'practice',\n",
       "  'different',\n",
       "  'context'],\n",
       " ['Design',\n",
       "  'information',\n",
       "  'security',\n",
       "  'risk',\n",
       "  'management',\n",
       "  'program',\n",
       "  'organization'],\n",
       " ['Implement', 'information', 'security', 'risk', 'management', 'roadmap'],\n",
       " ['Manage',\n",
       "  'information',\n",
       "  'security',\n",
       "  'risk',\n",
       "  'assessment',\n",
       "  'consulting',\n",
       "  'contract'],\n",
       " ['Compare', 'risk', 'assessment', 'technique'],\n",
       " ['Discuss', 'law', 'affecting', 'digital', 'forensics'],\n",
       " ['Analyze', 'concept', 'computer', 'digital', 'forensics'],\n",
       " ['Evaluate', 'current', 'computer', 'digital', 'forensics', 'tool'],\n",
       " ['Conduct',\n",
       "  'software',\n",
       "  'hardware',\n",
       "  'based',\n",
       "  'digital',\n",
       "  'forensic',\n",
       "  'analysis'],\n",
       " ['Evaluate', 'web', 'cloud', 'based', 'digital', 'forensic', 'tool'],\n",
       " ['Assess', 'digital', 'forensics', 'mobile', 'device', 'application'],\n",
       " ['Discuss', 'security', 'management', 'policy', 'best', 'practice'],\n",
       " ['Analyze',\n",
       "  'implement',\n",
       "  'Business',\n",
       "  'Continuity',\n",
       "  'Planning',\n",
       "  '(',\n",
       "  'BCP',\n",
       "  ')',\n",
       "  'Disaster',\n",
       "  'Recovery',\n",
       "  'Planning',\n",
       "  '(',\n",
       "  'DRP',\n",
       "  ')'],\n",
       " ['Criticize', 'legal', 'ethical', 'implication', 'security', 'management'],\n",
       " ['Apply', 'risk', 'evaluation', 'mitigation', 'strategy'],\n",
       " ['Apply', 'ISMS', 'standard'],\n",
       " ['Analyze', 'risk', 'management', 'auditing', 'technique'],\n",
       " ['Assess', 'vulnerability', 'hardware', 'device', 'system'],\n",
       " ['Analyze', 'attack', 'hardware', 'system'],\n",
       " ['Integrate', 'hardware', 'security', 'measure', 'design', 'metric'],\n",
       " ['Apply',\n",
       "  'detection',\n",
       "  ',',\n",
       "  'prevention',\n",
       "  'isolation',\n",
       "  'method',\n",
       "  'hardware',\n",
       "  'attack'],\n",
       " ['Evaluate', 'security', 'trust', 'hardware', 'system'],\n",
       " ['Describe', 'database', 'security', 'model', 'architecture'],\n",
       " ['Analyze', 'security', 'vulnerability', 'database'],\n",
       " ['Apply', 'database', 'security', 'model', 'policy', 'modern', 'database'],\n",
       " ['Discuss',\n",
       "  'data',\n",
       "  'application',\n",
       "  'auditing',\n",
       "  'procedure',\n",
       "  'database',\n",
       "  'security'],\n",
       " ['Compare', 'various', 'database', 'security', 'defense', 'mechanism'],\n",
       " ['Evaluate', 'option', 'needed', 'security', 'solution'],\n",
       " ['Compare', 'various', 'security', 'mechanism'],\n",
       " ['Apply',\n",
       "  'current',\n",
       "  'security',\n",
       "  'solution',\n",
       "  'address',\n",
       "  'certain',\n",
       "  'requirement'],\n",
       " ['Analyze', 'performance', 'applied', 'security', 'solution'],\n",
       " ['Explain', 'basic', 'principle', 'data', 'mining', 'process'],\n",
       " ['Prepare', 'data', 'mining', 'exploration'],\n",
       " ['Use',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'technique',\n",
       "  'modern',\n",
       "  'tool',\n",
       "  'discover',\n",
       "  'trend',\n",
       "  'pattern',\n",
       "  'realistic',\n",
       "  'datasets'],\n",
       " ['Evaluate',\n",
       "  'different',\n",
       "  'data',\n",
       "  'mining',\n",
       "  'models/techniques',\n",
       "  'respect',\n",
       "  'performance',\n",
       "  'accuracy'],\n",
       " ['Function', 'team', 'communicate', 'effectively', 'written', 'oral', 'form']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Array of all the PLOs and ULOs (We can couple them together as we're trying to identify Bloom/Solo level here)\n",
    "lo_sentence_array = []\n",
    "\n",
    "# TODO: train CLO classification with all data instead of just one course.\n",
    "for table in document.tables:\n",
    "    for row in table.rows:\n",
    "        for cell in row.cells[1:]:\n",
    "            tokens = nltk.word_tokenize(cell.text)\n",
    "            cleaned_tokens = [lemmatizer.lemmatize(token) for token in tokens if token.lower() not in stop_words]\n",
    "            lo_sentence_array.append(cleaned_tokens)\n",
    "\n",
    "# build the vocabulary and train the model\n",
    "# IMPORTANT, N0TE THAT sg=1 flag specifies Word2Vec to use the Skip Gram Model as designated by the LSTM paper.\n",
    "model = Word2Vec(sentences=lo_sentence_array,vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# train the model with the course's ULOs and PLOs.\n",
    "model.train([tokens], total_examples=len([tokens]), epochs=10)\n",
    "\n",
    "lo_sentence_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "{'<pad>': 0, 'the': 1, 'wide': 2, 'road': 3, 'shimmered': 4, 'in': 5, 'hot': 6, 'sun': 7}\n",
      "{0: '<pad>', 1: 'the', 2: 'wide', 3: 'road', 4: 'shimmered', 5: 'in', 6: 'hot', 7: 'sun'}\n",
      "[1, 2, 3, 4, 5, 1, 6, 7]\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "## training data LO\n",
    "## sentence = \"use big data streaming technologies.\"\n",
    "## word = \"apply\"\n",
    "## categories = [\"Remembering\", \"Understanding\", \"Applying\", \"Analysing\", \"Evaluating\", \"Creating\"]\n",
    "\n",
    "\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "sentence = \"The wide road shimmered in the hot sun\"\n",
    "tokens = list(sentence.lower().split())\n",
    "print(len(tokens))\n",
    "\n",
    "vocab, index = {}, 1  # start indexing from 1\n",
    "vocab['<pad>'] = 0  # add a padding token\n",
    "for token in tokens:\n",
    "  if token not in vocab:\n",
    "    vocab[token] = index\n",
    "    index += 1\n",
    "vocab_size = len(vocab)\n",
    "print(vocab)\n",
    "\n",
    "inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "print(inverse_vocab)\n",
    "\n",
    "example_sequence = [vocab[word] for word in tokens]\n",
    "print(example_sequence)\n",
    "\n",
    "window_size = 2\n",
    "positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "      example_sequence,\n",
    "      vocabulary_size=vocab_size,\n",
    "      window_size=window_size,\n",
    "      negative_samples=0)\n",
    "print(len(positive_skip_grams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/edward/.local/lib/python3.8/site-packages (4.3.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/edward/.local/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/edward/.local/lib/python3.8/site-packages (from gensim) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/edward/.local/lib/python3.8/site-packages (from gensim) (1.22.3)\n",
      "Requirement already satisfied: spacy in /home/edward/.local/lib/python3.8/site-packages (3.5.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (1.22.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (2.30.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (45.2.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (0.10.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (4.63.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (2.4.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/edward/.local/lib/python3.8/site-packages (from spacy) (8.1.10)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/edward/.local/lib/python3.8/site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/edward/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/edward/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.11.28)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/edward/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/edward/.local/lib/python3.8/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/edward/.local/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/edward/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/edward/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-17 21:29:43.937860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-17 21:29:44.749719: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 6.5 MB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /home/edward/.local/lib/python3.8/site-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.63.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.30.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (45.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/edward/.local/lib/python3.8/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/edward/.local/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/edward/.local/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/edward/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/edward/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2019.11.28)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/edward/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/edward/.local/lib/python3.8/site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/edward/.local/lib/python3.8/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/edward/.local/lib/python3.8/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "## packages to install\n",
    "\n",
    "pip install gensim\n",
    "pip install spacy\n",
    "python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comment out if breaking:\n",
    "# import spacy\n",
    "# spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code loads the vector file into the word_vectors variable\n",
    "## Download the vector file from https://fasttext.cc/docs/en/english-vectors.html (first file on the website), unzip the file and store in your local development folder\n",
    "## Note: This piece of code may take upto an hour or two to run depending on your pc specs.\n",
    "## My i5 8th gen with 8gig ram took 58mins to run.\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# Path to the downloaded .vec file\n",
    "# path_to_vectors = 'wiki-news-300d-1M.vec'\n",
    "path_to_vectors = 'wiki.en.vec'\n",
    "# Load the word vectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format(path_to_vectors)\n",
    "\n",
    "# Find similar words\n",
    "similar_words = word_vectors.most_similar('cat')\n",
    "\n",
    "# Calculate word similarity\n",
    "similarity = word_vectors.similarity('cat', 'dog')\n",
    "\n",
    "# Perform vector arithmetic\n",
    "result = word_vectors['king'] - word_vectors['man'] + word_vectors['woman']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import re\n",
    "import string\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "## training data LO\n",
    "## sentence = \"use big data streaming technologies.\"\n",
    "## word = \"apply\"\n",
    "## categories = [\"Remembering\", \"Understanding\", \"Applying\", \"Analysing\", \"Evaluating\", \"Creating\"]\n",
    "\n",
    "\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "SEED = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def generate_skipgrams(sentence):\n",
    "    tokens = list(sentence.lower().split())\n",
    "    print(len(tokens))\n",
    "\n",
    "    vocab, index = {}, 1  # start indexing from 1\n",
    "    vocab['<pad>'] = 0  # add a padding token\n",
    "    for token in tokens:\n",
    "      if token not in vocab:\n",
    "        vocab[token] = index\n",
    "        index += 1\n",
    "    vocab_size = len(vocab)\n",
    "    print(vocab)\n",
    "\n",
    "    inverse_vocab = {index: token for token, index in vocab.items()}\n",
    "    print(inverse_vocab)\n",
    "\n",
    "    example_sequence = [vocab[word] for word in tokens]\n",
    "    print(example_sequence)\n",
    "\n",
    "    window_size = 2\n",
    "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
    "          example_sequence,\n",
    "          vocabulary_size=vocab_size,\n",
    "          window_size=window_size,\n",
    "          negative_samples=0)\n",
    "    \n",
    "    return positive_skip_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "## Function to identify verbs in a sentence\n",
    "def identify_verbs(sentence):\n",
    "    # Load the English language model in spaCy\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    \n",
    "    # Process the sentence using spaCy\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    # Extract the verbs from the processed sentence\n",
    "    verbs = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
    "    \n",
    "    return verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apply', 'learn']\n",
      "Sentence:  apply common data analytics and machine learning algorithms in a big data environment.  Identified blooms level:  applying\n",
      "['use']\n",
      "Sentence:  use big data streaming technologies.  Identified blooms level:  applying\n"
     ]
    }
   ],
   "source": [
    "## Main piece of code that performs the mapping \n",
    "\n",
    "sentences = [\n",
    "    \"apply common data analytics and machine learning algorithms in a big data environment.\",\n",
    "    \"use big data streaming technologies.\"\n",
    "]\n",
    "# wiki word vectors no uppercase\n",
    "bloom_levels = [\"remembering\", \"understanding\", \"applying\", \"analysing\", \"evaluating\", \"creating\"]\n",
    "\n",
    "# identified_levels = []\n",
    "final_level = None\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    verbs = identify_verbs(sentences[i])\n",
    "    print(verbs)\n",
    "    score = 0\n",
    "    for j in range(len(verbs)):\n",
    "        for k in range(len(bloom_levels)):\n",
    "            similarity_score = word_vectors.similarity(verbs[j], bloom_levels[k])\n",
    "            if similarity_score >= score:\n",
    "                score=similarity_score\n",
    "                final_level = bloom_levels[k]\n",
    "    print(\"Sentence: \", sentences[i], \" Identified blooms level: \", final_level)\n",
    "\n",
    "\n",
    "### Todos\n",
    "# Find a way to use skipgrams\n",
    "# This method only works for blooms since this paper is only based on blooms mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx2txt\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# load in the Word document using docx2txt\n",
    "doc_text = docx2txt.process(CURRENT_MAPPING)\n",
    "\n",
    "# preprocess the text using NLTK\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# tokenize the text and remove stop words and non-alphabetic characters\n",
    "tokens = [word.lower() for word in word_tokenize(doc_text) if word.isalpha() and word.lower() not in stop_words]\n",
    "\n",
    "# lemmatization\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "\n",
    "# convert tokens back to single string format\n",
    "corpus = ' '.join(lemmatized_tokens)\n",
    "\n",
    "# create a tokenizer and fit on the corpus\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([corpus])\n",
    "\n",
    "# convert the text to a sequence of integers\n",
    "# sequences = tokenizer.texts_to_sequences([corpus])\n",
    "\n",
    "# pad the sequences to have a fixed length\n",
    "max_length = 50\n",
    "# padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# LSTM model\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Embedding(10000, 16),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2), # Dropout rate set to 0.2 as specified from the paper\n",
    "    tf.keras.layers.Dense(6, activation='softmax')\n",
    "])\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length))\n",
    "model.add(LSTM(units=64, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "# RMS Optimizer as specified by the paper.\n",
    "optimizer = RMSprop(learning_rate=0.001)\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "# X_train and y_train are assumed to be already defined\n",
    "# \n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
